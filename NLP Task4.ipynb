{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.gutenberg.org/files/98/98-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=request.urlopen(url)\n",
    "raw=response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens=word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'A', 'Tale', 'of', 'Two', 'Cities', ',', 'by', 'Charles', 'Dickens', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.', 'Title', ':', 'A', 'Tale', 'of', 'Two', 'Cities', 'A', 'Story', 'of', 'the', 'French', 'Revolution', 'Author', ':', 'Charles', 'Dickens', 'Release', 'Date', ':', 'January', ',', '1994', '[', 'eBook', '#', '98', ']', '[', 'Most', 'recently', 'updated', ':', 'December', '20', ',', '2020', ']', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'UTF-8', 'Produced', 'by', ':', 'Judith', 'Boss', 'and', 'David', 'Widger', '*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'A', 'TALE', 'OF', 'TWO', 'CITIES', '*', '*', '*', 'A', 'TALE', 'OF', 'TWO', 'CITIES', 'A', 'STORY', 'OF', 'THE', 'FRENCH', 'REVOLUTION', 'By', 'Charles', 'Dickens', 'CONTENTS', 'Book', 'the', 'First', '--', 'Recalled', 'to', 'Life', 'CHAPTER', 'I', 'The', 'Period', 'CHAPTER', 'II']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### beautiful soup https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful soup\n",
    "# preprocessing- RE to clean any html tags or unnecessary char sequences\n",
    "#POS tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemming -Porter, Regex, Lancaster, Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "porter.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joyou'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('joyous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cacti'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('cacti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "joy\n",
      "cact\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lancan=LancasterStemmer()\n",
    "print(lancan.stem('happiness'))\n",
    "print(lancan.stem('joyous'))\n",
    "print(lancan.stem('cacti'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sing\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg=RegexpStemmer('ing$')\n",
    "print(reg.stem('Singing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bonjour'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball=SnowballStemmer('french')\n",
    "snowball.stem('Bonjoura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', 'the', 'best', 'of', 'times,', 'it', 'was', 'the', 'worst', 'of', 'times,', 'it', 'was', 'the', 'ag', 'of', 'wisdom,', 'it', 'was', 'the', 'ag', 'of', 'foolishness,', 'it', 'was', 'the', 'epoch', 'of', 'belief,', 'it', 'was', 'the', 'epoch', 'of', 'incredulity,', 'it', 'was', 'the', 'season', 'of', 'light,', 'it', 'was', 'the', 'season', 'of', 'darkness,', 'it', 'was', 'the', 'spring', 'of', 'hop', ',', 'it', 'was', 'the', 'wint', 'of', 'despair,', 'we', 'had', 'everyth', 'bef', 'us,', 'we', 'had', 'noth', 'bef', 'us,', 'we', 'wer', 'al', 'going', 'direct', 'to', 'heaven,', 'we', 'wer', 'al', 'going', 'direct', 'the', 'oth', 'way—in', 'short,', 'the', 'period', 'was', 'so', 'far', 'lik', 'the', 'pres', 'period,', 'that', 'som', 'of', 'it', 'noisiest', 'auth', 'insist', 'on', 'it', 'being', 'received,', 'for', 'good', 'or', 'for', 'evil,', 'in', 'the', 'superl', 'degr', 'of', 'comparison', 'only.']\n"
     ]
    }
   ],
   "source": [
    "para=\"\"\"\n",
    "It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch \n",
    "of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope\n",
    ", it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we \n",
    "were all going direct the other way—in short, the period was so far like the present period, that some of its noisiest \n",
    "authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\n",
    "\"\"\"\n",
    "stems=[lancan.stem(word) for word in para.split()]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "lemma.lemmatize('am',pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n",
      "corpus\n",
      "good\n",
      "good\n",
      "best\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('works'))\n",
    "print(lemma.lemmatize('corpora'))\n",
    "print(lemma.lemmatize('good',pos='a'))\n",
    "print(lemma.lemmatize('better',pos='a'))\n",
    "print(lemma.lemmatize('best',pos='a')) # lematizer not stemming best to good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strip\n",
      "stripe\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize(\"stripes\", 'v')) # as a verb \n",
    "print(lemma.lemmatize(\"stripes\", 'n')) # as a noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('working',pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "para=\"\"\"In word processing and desktop publishing, a hard return or paragraph break indicates a new paragraph, to be distinguished from the soft return at the end of a line internal to a paragraph. This distinction allows word wrap to automatically re-flow text as it is edited, without losing paragraph breaks. The software may apply vertical white space or indenting at paragraph breaks, depending on the selected style.\n",
    "\n",
    "How such documents are actually stored depends on the file format. For example, HTML uses the <p> tag as a paragraph container. In plaintext files, there are two common formats. The pre-formatted text will have a newline at the end of every physical line, and two newlines at the end of a paragraph, creating a blank line. An alternative is to only put newlines at the end of each paragraph, and leave word wrapping up to the application that displays or processes the text.\n",
    "\n",
    "A line break that is inserted manually, and preserved when re-flowing, may still be distinct from a paragraph break, although this is typically not done in prose. HTML's <br /> tag produces a line break without ending the paragraph; the W3C recommends using it only to separate lines of verse (where each \"paragraph\" is a stanza), or in a street address\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'word', 'processing', 'and', 'desktop', 'publishing,', 'a', 'hard', 'return', 'or', 'paragraph', 'break', 'indicates', 'a', 'new', 'paragraph,', 'to', 'be', 'distinguished', 'from', 'the', 'soft', 'return', 'at', 'the', 'end', 'of', 'a', 'line', 'internal', 'to', 'a', 'paragraph.', 'This', 'distinction', 'allows', 'word', 'wrap', 'to', 'automatically', 're-flow', 'text', 'a', 'it', 'is', 'edited,', 'without', 'losing', 'paragraph', 'breaks.', 'The', 'software', 'may', 'apply', 'vertical', 'white', 'space', 'or', 'indenting', 'at', 'paragraph', 'breaks,', 'depending', 'on', 'the', 'selected', 'style.', 'How', 'such', 'document', 'are', 'actually', 'stored', 'depends', 'on', 'the', 'file', 'format.', 'For', 'example,', 'HTML', 'us', 'the', '<p>', 'tag', 'a', 'a', 'paragraph', 'container.', 'In', 'plaintext', 'files,', 'there', 'are', 'two', 'common', 'formats.', 'The', 'pre-formatted', 'text', 'will', 'have', 'a', 'newline', 'at', 'the', 'end', 'of', 'every', 'physical', 'line,', 'and', 'two', 'newlines', 'at', 'the', 'end', 'of', 'a', 'paragraph,', 'creating', 'a', 'blank', 'line.', 'An', 'alternative', 'is', 'to', 'only', 'put', 'newlines', 'at', 'the', 'end', 'of', 'each', 'paragraph,', 'and', 'leave', 'word', 'wrapping', 'up', 'to', 'the', 'application', 'that', 'display', 'or', 'process', 'the', 'text.', 'A', 'line', 'break', 'that', 'is', 'inserted', 'manually,', 'and', 'preserved', 'when', 're-flowing,', 'may', 'still', 'be', 'distinct', 'from', 'a', 'paragraph', 'break,', 'although', 'this', 'is', 'typically', 'not', 'done', 'in', 'prose.', \"HTML's\", '<br', '/>', 'tag', 'produce', 'a', 'line', 'break', 'without', 'ending', 'the', 'paragraph;', 'the', 'W3C', 'recommends', 'using', 'it', 'only', 'to', 'separate', 'line', 'of', 'verse', '(where', 'each', '\"paragraph\"', 'is', 'a', 'stanza),', 'or', 'in', 'a', 'street', 'address']\n"
     ]
    }
   ],
   "source": [
    "stems=[lemma.lemmatize(word) for word in para.split()]\n",
    "print(stems)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
